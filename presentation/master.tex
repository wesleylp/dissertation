%******************************************************
% Header
%******************************************************

%Document type
\documentclass{beamer}

%Theme
%\usetheme{Madrid}

%Packages
\usepackage{etex}
\usepackage{mypresentation}							%SMT presentation style
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
% \usepackage[utf8]{inputenc}							%Language/input coding
% \usepackage[brazil, english]{babel}					%Brazilian Portuguese Language Package
% \usepackage[T1]{fontenc}							%Hyphenation
% \usepackage{graphicx}								%Graphic package
% %\usepackage{subfig}									%Subfloats
% \usepackage{color}									%Color package
% \usepackage{lmodern}								%Solve font problems
\usepackage{amssymb}								%Math symbols
\usepackage{amsthm}									%Theorem
% \usepackage{multimedia}								%Multimedia package
% \usepackage{array}									%For tabular
%\usepackage{pgfplotstable}								%For extracting tables from csv
\usepackage{tikz}										%Tikz graphic library
\usetikzlibrary{patterns, calc}							%Tikz patterns and computations

\usepackage{multirow}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{subfig}
\usepackage{myMacros}
\usepackage{hyperref}

\graphicspath{{/home/wesley/Dropbox/Mestrado/dissertation/text/v0/images/}}

%******************************************************
% Math operators
%******************************************************
% \DeclareMathOperator{\tr}{tr}								%Trace
% \DeclareMathOperator{\diag}{diag}							%Diag
% \DeclareMathOperator*{\argmax}{arg\,max}					%Argmax
% \DeclareMathOperator*{\argmin}{arg\,min}					%Argmin
% \DeclareMathOperator{\sgn}{sgn}								%Signal function
% \newcommand{\Trm}{\mathrm{T}}								%Transpose
% \newcommand{\drm}{\mathrm{d}}								%Differential
% \newcommand{\erm}{\mathrm{e}}								%Exponential
% \newcommand{\jrm}{\mathrm{j}}								%Complex number

\newcommand\blfootnote[1]{%
	\begingroup
	\renewcommand\thefootnote{}\footnote{#1}%
	\addtocounter{footnote}{-1}%
	\endgroup
}


%******************************************************
% Title page
%******************************************************

%Title and subtitle
\title[Wesley L. Passos]{{\huge {Automatic {\it Aedes aegypti} Breeding Grounds Detection Using Computer Vision Techniques} }
	}

%Author
\author[]{
	Wesley Lobato Passos\\
	\vspace{5mm}
	\footnotesize{Eduardo A. B. da Silva \&
	Gabriel M. Araujo}
}



%Institute
\institute[SMT/COPPE/UFRJ]
{
	Signals, Multimedia, and Telecommunications Laboratory \newline
	COPPE/UFRJ
}

\date{February 27, 2019}
%******************************************************
% Section open
%******************************************************

\AtBeginSection[]
{
	\begin{frame}
		\frametitle{Sum√°rio}
		%\tableofcontents[currentsection, hideallsubsections]
		\tableofcontents[currentsection]
	\end{frame}
}

%******************************************************
% Main Body
%******************************************************

%Document Beginning
\begin{document}

  %% Front page logos.
  \MyLogos{0.60cm}

  %Title frame
  \begin{frame}
    \titlepage
  \end{frame}

  %% Smaller logos for the other slides.
  \MyLogos{0.30cm}

  %Table of Contents
  \begin{frame}
    \frametitle{Outline}
    \tableofcontents[hideallsubsections]
  \end{frame}



	%%============================================================================
	%% SECTION - Introduction
	%%============================================================================
	\section{Introduction}

		\begin{frame}\frametitle{Motivation}

			\begin{itemize}
				\item The arboviruses ({\bf dengue}, {\bf chikungunya}, {\bf zika}, and {\bf yellow fever})
				are one of the leading global health problem;
				\item the {\it Aedes aegypti} is the main {\bf vector} of such diseases;
				\item the best form of combat is {\bf eliminating} possible mosquito {\bf foci} proliferation;
				\item it can be {\bf expensive} and {\bf time-consuming} (therefore, {\bf inefficient});
				\item to use {\bf aerial images} and {\bf videos} captured by an {\bf UAV};
				\item {\bf automatic detection} of regions and objects with {potential mosquito breeding sites} in order to assist health agents;
				\item to apply {\bf computer vision} and {\bf machine learning} techniques.
		\end{itemize}

	\end{frame}


	%%==============================================================================
	%% SECTION - The Aedes aegypti
	%%==============================================================================
	\section{The Aedes aegypti}

	\begin{frame}
		\frametitle{Action of the Health's Department}

		The Health's Department follows an \textbf{internacional protocol} to combat arboviruses, in which they have routine actions, such as daily visits and strategic points, and emergency actions, when there is a case report.
		\newline

		The control methods are divided into
		\begin{itemize}
			\item Mechanical: displacement of object, sealing of water tank, etc
			\item Chemical: larvicide and insecticide/smoke repellency
			\item Biological: larvae and wolbachia
			\item Legal: with the support of justice
			\item Integrated: involving other secretariats
		\end{itemize}

		\vspace{3.5mm}
		The goal is to keep vector control below 1\%.
	\end{frame}

	\begin{frame}
		\frametitle{Final Product for the Government}

		We expect to deliver a \textbf{decision support system} that performs a scan in a predefined area and can identify and classify possible breeding sites according to the codes defined in the control model used by SVS.
		\newline

		In this way, indicate your \textbf{geographic positions} so that the expert evaluates and defines the actions to be taken in the property he identified.
		\newline

		The \textbf{main advantage} for the secretariat is in the legal control, when there is case notification and a property near the locality is abandoned or blocked.
	\end{frame}

	\begin{frame}
		\frametitle{Objects of Interest}


		\begin{table}[]
			\resizebox{\textwidth}{!}{%
			\begin{tabular}{@{}cc@{}}
				\toprule
				\textbf{Code} & \textbf{Description}                                                       \\ \midrule
				A1            & Water tank connected to the grid (high tanks)                              \\
				A2            & Deposits at ground level (barrel, tub, drum, tank, well)                   \\
				B             & Mobile containers (vases/jars, plates, drippings, drinking fountains, etc) \\
				C             & Fixed deposits (tanks, gutters, slabs, etc.)                               \\
				D1            & Tires and other rolling materials                                          \\
				D2            & Garbage (plastic containers, bottles, cans, scraps)                        \\
				E             & Natural deposits (bromeliads, bark, tree holes)                            \\ \bottomrule
				\end{tabular}
				}
		\end{table}
	\end{frame}




%%==============================================================================
%% SECTION - Vision Meets Unmanned Vehicles
%%==============================================================================
\section{Vision Meets Unmanned Vehicles}

	\subsection{Related works}

	\subsection{The CEFET dataset}

	\subsection{The MBG dataset}

		\begin{frame}\frametitle{}
			Due to the nature of our problem, we decided to use
			\begin{itemize}
				\item the downward vision system
				\item constant drone speed and height
				\item 4K (3.840 x 2.160) resolution and H.265 (maximum $30fps$)
			\end{itemize}

			\bigskip

			Some parameters were defined through a simple analyze:
			\begin{itemize}
				\item Height was defined as 10 meters based on object resolution, visualizing which would be the heigher altitude in which it is still possible to identify the smallest object of interest, a bottle
				\item Speed was defined as 15km/h based on the quantity of frames that contains the whole biggest object, a pool
			\end{itemize}
		\end{frame}


		\begin{frame}\frametitle{Flight plan details}
			We decided to use a trajectory that:
			\begin{itemize}
				\item covers an rectangular area, defined as the rectangle with minimum area that surrounds the given points of interest
				\item considers the horizontal GPS positioning accuracy, expanding the rectangular area to be sure to cover all the given points
				\item maps the rectangular area in a ``boustrophedon'' way, i.e., from right to left and from left to right in alternate parallel lines
				\item has an overlap that allows an object of interest not to be cut in at least one pass, considering its maximum size and aircraft vision positioning accuracy
				\item the drone does not change its orientation, only its direction
			\end{itemize}
		\end{frame}


		\begin{frame}
			\frametitle{Some measures to meet the specifications}
			\begin{figure}
				\centering
				\includegraphics[height=6.4cm]{flightplan.png}
			\end{figure}
		\end{frame}


		\begin{frame}
			\frametitle{Example}
			\begin{figure}
				\centering
				\includegraphics[height=8cm]{gremio.pdf}
			\end{figure}
		\end{frame}


		\begin{frame}
			\frametitle{Flight mission}
			\begin{figure}
				\centering
				\includegraphics[width=12cm]{missionlitchi.png}
			\end{figure}
		\end{frame}


		\begin{frame}
			\frametitle{}
			\begin{enumerate}
				\item Select the points of interest on Google Maps or Litchi Mission Hub
				\item Define drone height (desired 10m) and speed (suggested 15km/h)
				\item Project the flight plan remotely
				\item Import it to mission hub and save it after verify general parameters:
				\begin{itemize}
					\item Finish Action: RTH (return to home)
					\item Path Mode: Straight Lines
					\item Default Gimbal Pitch Mode: Disabled
				\end{itemize}
				\item Arrange the objects in the area, if necessary
				\item Verify other parameters such as:
				\begin{itemize}
					\item Resolution: 4K (3.840 x 2.160)
					\item Focus at infinity (do it manually by touching the screen on the horizon)
					\item White balance as sunny or cloudy, depending on the weather
				\end{itemize}
				\item Record video for camera calibration
				\item Open the mission on litchi app
				\item Press play
			\end{enumerate}
		\end{frame}


		\begin{frame}\frametitle{Projective Transformation}
			%
			\begin{itemize}
			 \item  A camera maps a point $\Mbf' = [X,Y,Z,1]^\Trm$ in the space into a point $\mbf' = [u,v,1]^\Trm$ through a projective transformation:
			 \begin{equation}
			\label{eq:projection}
			s\mbf' = \Asf[\Rsf~|~\tbf]\Mbf',
			\end{equation}
			\begin{itemize}
			 \item $s$ is an arbitrary scale factor;
			 \item $\Rsf$ and $\tbf$ are, respectively, the rotation matrix and the translation vector (extrinsic parameters), which relate the real-world coordinate system to the camera's coordinate system.
			\end{itemize}
			\end{itemize}
			%
			%
		\end{frame}

		\begin{frame}\frametitle{Pinhole Camera Model}
			%TODO: make my own image.
			%
			\begin{figure}[htb!]
				\center
				\includegraphics[width=.7\textwidth]{pinhole_camera_model.png}
				\label{fig:keypts_1} %\\[-0.2cm]
				\caption{Pinhole camera model. (source: OpenCV).}
				%\url{https://docs.opencv.org/3.4.1/d9/d0c/group__calib3d.html#ga3207604e4b1a1758aa66acb6ed5aa65d}
				\vspace{-3.5mm}
				% \href{https://docs.opencv.org/3.4.1/d9/d0c/group__calib3d.html#ga3207604e4b1a1758aa66acb6ed5aa65d}{[ref.: OpenCV documentation.]}
				\label{fig:undistort}
			\end{figure}
		\end{frame}


		\begin{frame}
			\frametitle{Intrinsic Parameters}
			\begin{itemize}
			 \item $\Asf$ is the the camera calibration matrix (intrinsic parameters):
			 \begin{equation}
			\Asf =
			\begin{bmatrix}
			\alpha & \gamma & u_0\\
			0 & \beta  & v_0\\
			0 &     0  & 1\\
			\end{bmatrix},
			\end{equation}
			\begin{itemize}
			 \item $[u_0,v_0]^\Trm$ denote the coordinates of the principal point,
			 \item $\alpha$ and $\beta$ the scaling factors in the $ u $ and $ v $ axes of the image, respectively,
			 \item $\gamma$ is the obliquity (degree of shear) of the two axes of the image.
			\end{itemize}
			\end{itemize}
		\end{frame}


		\begin{frame}\frametitle{Radial Distortion Compensation}
			\begin{itemize}
			 \item Conventional cameras usually have significant lens distortions, especially radial distortion.
			 \item Formulation:
			 \begin{itemize}
			  \item Let $(u,v)$ be the the ideal coordinates (free of distortion) of the pixel on the image, and
			  \item $(\breve{u},\breve{v})$ the actual coordinates of the observed image,
			  \item the ideal points are the projections of the points of the calibration standard according to the model given by Eq.~\eqref{eq:projection}.
			  \item Analogously, $(x,y)$ and $(\breve{x},\breve{y})$ are the normalized coordinates in the ideal (free of distortion) and real (distorted) images, respectively.
			  \item The radial distortion can be modeled as:
			\begin{align}
			\breve{x} &= x + x(k_1 r^2 + k_2 r^4) \\% + k_3 r^6)\\% + 2p_1 x y + p_2(r^2 + 2x^2), \\
			\breve{y} &= y + y(k_1 r^2 + k_2 r^4), % + k_3 r^6),% + p_1(r^2 + 2y^2) + 2 p_2 x y,
			\end{align}
			\item $k_1$ and $k_2$ are the radial distortion coefficients,
			\item $r^2 = (x^2 + y^2)$.
			 \end{itemize}
			\end{itemize}
		\end{frame}


		\begin{frame}
			\frametitle{Radial Distortion Compensation}
			%
			\begin{itemize}
			 \item The center of the radial distortion is located at the main point.
			 \item From $\breve{u} = \alpha \breve{x} + \gamma \breve{y} + u_0 $ and $\breve{v} = \beta \breve{y} + v_0$, and assuming $\gamma = 0$:
			  \begin{align}
			    \label{eq:u_dist}
			    \breve{u} &= u + (u-u_0)(k_1 r^2 + k_2 r^4 ) \\
			    \label{eq:v_dist}
			    \breve{v} &= v + (v-v_0)(k_1 r^2 + k_2 r^4 ).
			  \end{align}
			\end{itemize}
		\end{frame}


		\begin{frame}
			\frametitle{Zhang's Method}
			%
			\begin{itemize}
			 \item Make a first rough estimate of the intrinsic and extrinsic parameters of the camera
			 \item refine it by estimating the maximum likelihood
			 \begin{itemize}
			  \item Given $ n $ images of the calibration standard and considering $ m $ points in this standard,
			  \item assuming that the point images are corrupted by an i.i.d. noise
			  \item the maximum likelihood estimate can be obtained by minimizing the functional
			  %
			  \begin{equation}
			    \sum_{i=1}^{n}\sum_{j=1}^{m} \Vert \xbf_{ij} - \breve{\xbf}(\Asf, k_1, k_2, \Rsf_i, \tbf_i, \Xbf_j) \Vert^2
			    \label{eq:functional},
			  \end{equation}
			  \item $\breve{\xbf}(\Asf, k_1, k_2, \Rsf_i, \tbf_i, \Xbf_j)$ is the projection of point $\Xbf_j$, according to Eq.~\eqref{eq:projection},
			followed by the distortion modeled according to the Eqs.~\eqref{eq:u_dist} and~\eqref{eq:v_dist}
			  \item Minimize the functional in~\eqref{eq:functional} is a nonlinear optimization problem that can be solved through the algorithm of Levenberg-Marquardt.
			 \end{itemize}
			\end{itemize}
			%
		\end{frame}


		\begin{frame}\frametitle{Comparison: distorted frame $\times$ undistorted}
			\begin{figure}[htb!]
				\center
				\subfloat[]{\includegraphics[width=0.5\textwidth]{frame_420_pts.png}
					\label{fig:keypts_1}} %\\[-0.2cm]
					\subfloat[]{\includegraphics[width=0.5\textwidth]{frame_420_undistorted.png}%
					\label{fig:undistort_1}} %\\[-0.2cm]
				\label{fig:undistort}
			\end{figure}
		\end{frame}


		\begin{frame}\frametitle{Annotation}
			\begin{itemize}
				\item The frame-by-frame annotation of all acquired sequences is done with the Zframer system, as illustrated below.
			\end{itemize}
			\begin{figure}[htb]
				\centering
				\includegraphics[width=.98\columnwidth]{zframer_marking.png}
				\label{fig:zframer1}
			\end{figure}
		\end{frame}







		\begin{frame}\frametitle{Objects}
			\begin{figure}[htb]
				\centering
				\includegraphics[width=.1\linewidth]{garrafa1.png}
				\includegraphics[width=.2\linewidth]{garrafa2.png}
				\includegraphics[width=.1\linewidth]{pneu1.png}
				\includegraphics[width=.1\linewidth]{pneu3.png}\\
				\includegraphics[width=.1\linewidth]{pneu5.png}
				\includegraphics[width=.1\linewidth]{water1.png}
				\includegraphics[width=.1\linewidth]{water2.png}
				\includegraphics[width=.1\linewidth]{water3.png}
			% \includegraphics[width=.26\linewidth]{base4.png}
				\label{fig:objetos1}
			\end{figure}


		\end{frame}


	\subsection{Scenarios}

		\begin{frame}\frametitle{Scenarios}
			\begin{figure}[htb!]
				\centering
				\includegraphics[width=.35\linewidth]{base1.png}
				\includegraphics[width=.36\linewidth]{base2.png}\\
				\includegraphics[width=.35\linewidth]{base3.png}
			% \includegraphics[width=.26\linewidth]{../figures/base4.png}
				\label{fig:scenarios1}
			\end{figure}

		\end{frame}


\subsection{Camera Calibration: Zhang's Method}

% -----------------------------------------------------------------------------
% \frame{
%   \frametitle{Projection}
%   %
%   Considera-se que uma c√¢mera mapeia um ponto $\Mbf' = [X,Y,Z,1]^\Trm$ do espa√ßo no ponto $\mbf' = [u,v,1]^\Trm$ da imagem atrav√©s de uma transforma√ß√£o projetiva da forma:
%   %
%   \begin{equation}
%   \label{eq:projection}
%   s\mbf' = \Asf[\Rsf~|~\tbf]\Mbf',
%   \end{equation}
%   %
%   onde $s$ √© um fator de escala arbitr√°rio, $\Rsf$ e $\tbf$ s√£o, respectivamente, a matriz de rota√ß√£o e o vetor de transla√ß√£o (par√¢metros extr√≠nsecos),que relacionam o sistema de coordenadas do mundo real com o sistema de coordenadas da c√¢mera.
%   %
%   %
% }

% -----------------------------------------------------------------------------


% -----------------------------------------------------------------------------
% \frame{
%   \frametitle{Par√¢metros Intr√≠nsecos}
%     $\Asf$ √© a matriz de calibra√ß√£o da c√¢mera (par√¢metros intr√≠nsecos), definida por:
%     \begin{equation}
%       \Asf =
%       \begin{bmatrix}
% 	\alpha & \gamma & u_0\\
% 	0 & \beta  & v_0\\
% 	0 &     0  & 1\\
%       \end{bmatrix},
%     \end{equation}
%     com $[u_0,v_0]^\Trm$ denotando as coordenadas do ponto principal,
%     $\alpha$ e $\beta$ os fatores de escala nos eixos $u$ e $v$ da imagem, respectivamente,
%     e $\gamma$ √© a obliquidade (grau de cisalhamento) dos dois eixos da imagem.
% }

% -----------------------------------------------------------------------------
% \frame{
%   \frametitle{Compensa√ß√£o de Distor√ß√£o Radial}
%    C√¢meras convencionais geralmente possuem significantes distor√ß√µes de lentes, especialmente distor√ß√£o radial.
%
%    Sejam $(u,v)$ as coordenadas ideais (livre de distor√ß√£o) do pixel na imagem e $(\breve{u},\breve{v})$ as coordenadas correspondentes reais de imagem observada.
%
%     Os pontos ideais s√£o as proje√ß√µes dos pontos do padr√£o de calibra√ß√£o de acordo com o modelo dado pela Eq.~\eqref{eq:projection}.
%
%    Analogamente, $(x,y)$ e $(\breve{x},\breve{y})$ s√£o as coordenadas normalizadas nas imagens ideal (livre de distor√ß√£o) e real (distorcida), respectivamente.
%
%    A distor√ß√£o radial pode ser modelada como:
%    \begin{align}
%     \breve{x} &= x + x(k_1 r^2 + k_2 r^4) \\% + k_3 r^6)\\% + 2p_1 x y + p_2(r^2 + 2x^2), \\
%     \breve{y} &= y + y(k_1 r^2 + k_2 r^4), % + k_3 r^6),% + p_1(r^2 + 2y^2) + 2 p_2 x y,
%    \end{align}
% onde $k_1$ e $k_2$ s√£o os coeficientes de distor√ß√£o radial e $r^2 = (x^2 + y^2)$.
%
%
% }

% -----------------------------------------------------------------------------
% \frame{
%   \frametitle{Compensa√ß√£o de Distor√ß√£o Radial}
%     %
%     O centro da distor√ß√£o radial est√° localizado no ponto principal.
%
%     De $\breve{u} = \alpha \breve{x} + \gamma \breve{y} + u_0 $ e $\breve{v} = \beta \breve{y} + v_0$, assumindo $\gamma = 0$,
%     pode-se escrever que
%     %
%     \begin{align}
%       \label{eq:u_dist}
%       \breve{u} &= u + (u-u_0)(k_1 r^2 + k_2 r^4 ) \\
%       \label{eq:v_dist}
%       \breve{v} &= v + (v-v_0)(k_1 r^2 + k_2 r^4 ).
%     \end{align}
%
%
% }

% -----------------------------------------------------------------------------
% \frame{
%    \frametitle{M√©todo de Zhang}
%     %
%     O m√©todo de Zhang consiste em fazer, primeiramente, uma estimativa grosseira dos par√¢metros intr√≠nsecos e extr√≠nsecos da c√¢mera para depois refin√°-la atrav√©s da estimativa da m√°xima verossimilhan√ßa.
%
%     Dadas $n$ imagens do padr√£o de calibra√ß√£o e considerando $m$ pontos neste padr√£o,
%     assumindo que as imagens dos pontos est√£o corrompidas por um ru√≠do independente e identicamente distribu√≠do, a estimativa de m√°xima verossimilhan√ßa pode ser obtida minimizando o funcional
%     %
%     \begin{equation}
%       \sum_{i=1}^{n}\sum_{j=1}^{m} \Vert \xbf_{ij} - \breve{\xbf}(\Asf, k_1, k_2, \Rsf_i, \tbf_i, \Xbf_j) \Vert^2
%       \label{eq:functional},
%     \end{equation}
%     %
%     onde $\breve{\xbf}(\Asf, k_1, k_2, \Rsf_i, \tbf_i, \Xbf_j)$ √© a proje√ß√£o do ponto $\Xbf_j$, de acordo com a Eq.~\eqref{eq:projection},
%     seguido da distor√ß√£o modelada de acordo com as Eqs.~\eqref{eq:u_dist} e~\eqref{eq:v_dist}.
%
%     Minimizar o funcional em~\eqref{eq:functional} √© um problema de otimiza√ß√£o n√£o-linear que pode ser resolvido atrav√©s do algoritmo de Levenberg-Marquardt.
%
% }

% -----------------------------------------------------------------------------






%%==============================================================================
%% SECTION - Object Detection with Deep Learning
%%==============================================================================
	\section{Object Detection with Deep Learning}

		\subsection{Deep Learning}

			\begin{frame}\frametitle{Convolutional Neural Networks}
				\begin{figure}[htb]
					\centering
					\includegraphics[width=.4\columnwidth]{conv_eng.pdf}
					\includegraphics[width=6.5cm]{drone-persp2.png}
					\label{fig:zframer1}
				\end{figure}
			\end{frame}

%%==============================================================================
%% SECTION - Results and Discussions
%%==============================================================================
	\section{Results and Discussions}

		\subsection{Evaluation}

			\begin{frame}\frametitle{Intersection over Union (IoU)}
				\begin{itemize}
					\item Evaluate the model regarding object localization;
					\item Detections are considered as TP if the IoU $\geq$ threshold and as FP otherwise.
				\end{itemize}
				%
				\begin{figure}[htb]
					\centering
					\includegraphics[width=.6\linewidth]{IoU.pdf}
					\label{fig:IoU}
				\end{figure}

			\end{frame}


		\subsection{Quantitative results}

		\begin{frame}\frametitle{Results for CEFET dataset}
			\begin{table}[b!]
				\centering
				\resizebox{\textwidth}{!}{%
				\begin{tabular}{@{}c|l|c|ccc|cc@{}}
				\toprule
															 &                        & backbone & mAP   & mAP$_{50}$ & mAP$_{75}$ & mAP$_{\rm M}$ & mAP$_{\rm L}$ \\
															 \hline
				\multirow{3}{*}{train} & Faster R-CNN (no aug.) & R-50-C4 &  89.86 & 90.19 & 90.19 & 86.15 & 92.16 \\
															 & Faster R-CNN           & R-50-C4 & 89.11 & 89.84 & 89.84 &  87.32 & 90.34  \\
															 & Faster R-CNN           & R-101-C4 & 88.95 & 89.48 & 89.48 &  87.52 & 91.02 \\
				\hline
				\multirow{3}{*}{test}  & Faster R-CNN (no aug.) & R-50-C4  & 43.81 & 62.25 & 53.64 &  34.46 & 59.56  \\
															 & Faster R-CNN           & R-50-C4  & 47.38 & 64.16 & 57.70 &  38.42 & 61.85\\
															 & Faster R-CNN           & R-101-C4 & 49.31 & 66.68 & 62.61 &  39.46 & 65.21 \\
				\bottomrule
				\end{tabular}
				}
				\label{tab:results_CEFET}
				\end{table}
		\end{frame}


		\begin{frame}%\frametitle{Quantitative results}
			\begin{figure}[htb!]
				\centering
				\includegraphics[width=.35\linewidth, trim={0 0 0 0},clip]{pr_curve_e2e_faster_rcnn_R_101_C4_1x_cocostyle_zoom_1.pdf}~
				\includegraphics[width=.35\linewidth, trim={0 0 0 0},clip]{pr_curve_e2e_faster_rcnn_R_101_C4_1x_cocostyle_zoom_2.pdf}\\
				\vspace{.5mm}
				\includegraphics[width=.7\linewidth, trim={0 0 0 0},clip]{pr_curve_e2e_faster_rcnn_R_101_C4_1x_cocostyle.pdf}
			% 	\includegraphics[width=.5\linewidth]{base4.png}
				% \caption{Precision-recall curve for R-101-C4 at various IoUs.}
				\label{fig:pr_R101C4}
			\end{figure}
			%
			%
		\end{frame}


		\begin{frame}%\frametitle{Quantitative results}
			\begin{figure}[htb!]
				\centering
				\includegraphics[width=.51\linewidth]{pr_curve_comp_50.pdf}
				\includegraphics[width=.51\linewidth]{pr_curve_comp_75.pdf}
				% \caption{Precision-recall curve at IoU = 0.50.}
				% \caption{Precision-recall curve at IoU = 0.75.}
				\label{fig:prec-rec_curve}
			\end{figure}
			%
			%
			%
		\end{frame}


	\subsection{Visual analysis}

		\begin{frame}\frametitle{Hard example}
			\begin{figure}[h!]
				\centering
				\includegraphics[width=.55\textwidth,trim={0 2.9cm 0 2.4cm},clip]{_vis_results/e2e_faster_rcnn_R_101_C4_1x_cocostyle/img_30.pdf}
				% \caption{Hard example.}
				\label{fig:hard}
			\end{figure}
			%
		\end{frame}


		\begin{frame}\frametitle{Comparison among models}
			\begin{figure}[htb!]
				\centering
				\includegraphics[width=.5\textwidth,trim={0 2.9cm 0 2.4cm},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle_NO-AUG/img_1.pdf}
				\includegraphics[width=.5\textwidth,trim={0 2.9cm 0 2.4cm},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle/img_1.pdf}\\
				\vspace{3mm}
				\includegraphics[width=.5\textwidth,trim={0 2.9cm 0 2.4cm},clip]{_vis_results/e2e_faster_rcnn_R_101_C4_1x_cocostyle/img_1.pdf}
				% \caption{Detection improvement over the models.}
  			\label{fig:improv_1}
			\end{figure}
		\end{frame}


		\begin{frame}\frametitle{Comparison among models}
			\begin{figure}[htb!]
				\centering
				\includegraphics[width=.5\textwidth,trim={0 2.9cm 0 2.4cm},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle_NO-AUG/img_12.pdf}
				\includegraphics[width=.5\textwidth,trim={0 2.9cm 0 2.4cm},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle/img_12.pdf}
				\vspace{3mm}
				\includegraphics[width=.5\textwidth,trim={0 2.9cm 0 2.4cm},clip]{_vis_results/e2e_faster_rcnn_R_101_C4_1x_cocostyle/img_12.pdf}
				% \caption{Another detection improvement over the models.}
  			\label{fig:improv_2}
			\end{figure}
		\end{frame}


		\begin{frame}\frametitle{Some false positives cases}
			\begin{figure}[htb!]
				\centering
				\includegraphics[width=.5\textwidth,trim={0 0 0 0},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle_NO-AUG/img_78.pdf}
				\includegraphics[width=.5\textwidth,trim={0 0 0 0},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle/img_78.pdf}
				\vspace{.1mm}
				\includegraphics[width=.5\textwidth,trim={0 0 0 0},clip]{_vis_results/e2e_faster_rcnn_R_101_C4_1x_cocostyle/img_78.pdf}
				% \caption{Some false positives cases.}
				\label{fig:FP_cases}
			\end{figure}
		\end{frame}


		\begin{frame}\frametitle{High occlusion example}
			\begin{figure}[htb!]
				\centering
				\includegraphics[width=.5\textwidth,trim={0 0 0 0},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle_NO-AUG/img_127.pdf}
				\includegraphics[width=.5\textwidth,trim={0 0 0 0},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle/img_127.pdf}
				\vspace{.1mm}
				\includegraphics[width=.5\textwidth,trim={0 0 0 0},clip]{_vis_results/e2e_faster_rcnn_R_101_C4_1x_cocostyle/img_127.pdf}
				% \caption{High occlusion example.}
  			\label{fig:occlusion}
			\end{figure}
		\end{frame}


		\begin{frame}\frametitle{Wrong false positive}
			\begin{figure}[h!]
				\centering
				\includegraphics[width=.8\textwidth,trim={0 0 0 0},clip]{_vis_results/e2e_faster_rcnn_R_50_C4_1x_cocostyle_NO-AUG/img_133.pdf}
				% \caption{Wrong false positive.}
				\label{fig:wrong_fp}
			\end{figure}
			%
		\end{frame}

%%==============================================================================
%% SECTION - Conclusion and Future Works
%%==============================================================================
	\section{Conclusion and Future Works}

		\begin{frame}
			\frametitle{Conclusion}
			\begin{itemize}
				\item To deliver a decision support system
				\item To indicate your geographic positions
				\item To facilitate scan abandoned or blocked areas
			\end{itemize}

		\begin{itemize}
			\item This work described the problem of automatic detection, by computer vision techniques, of mosquitoes breeding sites.
			\item We pointed to the need to create a database to attack the problem, containing videos with several objects that accumulate clean water scattered in several scenarios.
			\item For this, the use of a VANT was considered, which allows the acquisition of videos covering a wide geographical area.
			\item All videos are manually annotated with the help of free software, allowing the training of different critical object detector algorithms for the application of interest.
		\end{itemize}

		\end{frame}

		\begin{frame}
			\frametitle{THANK YOU!}
			\centering
			Wesley Lobato Passos\\
			wesley.lpassos@gmail.com
		\end{frame}



\end{document}